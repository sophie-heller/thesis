{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_csv_filtered(file_path, date, sensorid):\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a DataFrame (reading only relevant columns), sets 'timestamp' as index,\n",
    "    and returns the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the directory to the building.\n",
    "    - date (str): Folder name (date of the measurements)\n",
    "    - sensor (str): File name (sensor ID) without .csv extension.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with 'timestamp' as index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read CSV file into DataFrame\n",
    "    df = pd.read_csv(f\"{file_path}\\\\daily\\\\{date}\\\\{sensorid}.csv\", header=None, names=['timestamp', sensorid, 'status'], usecols=[0, 1, 4], parse_dates=['timestamp'])\n",
    "\n",
    "    # Set 'timestamp' as index\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and save one csv per sensor\n",
    "path = os.getcwd()\n",
    "#print(root_path)\n",
    "#print(os.listdir(root_path))\n",
    "\n",
    "building_name = \"seeweg\"        # name of the folder in the \"measurements\" folder\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), f\"measurements\\{building_name}_data\")\n",
    "\n",
    "date_list = os.listdir(f\"{file_path}\\\\daily\")                       # List of the dates where the measuremenst were taken\n",
    " \n",
    "\n",
    "csv_filename_list = os.listdir(f\"{file_path}\\\\daily\\\\2024-06-01\")                                          # List of the names of the files in one date folder, constant over dates\n",
    "\n",
    "sensor_id_list = [sensor_filename.replace(\".csv\", \"\") for sensor_filename in csv_filename_list]     # removes the .csv ending of the filenames in the folder\n",
    "\n",
    "\n",
    "\"\"\"for n in range(len(sensor_id_list)):\n",
    "    merged_test = pd.DataFrame()\n",
    "    for j in range(len(date_list)):\n",
    "        test = read_csv_filtered(file_path, date_list[j], sensor_id_list[n])\n",
    "        merged_test = pd.concat([merged_test, test])\n",
    "        print(len(merged_test)-len(test))\n",
    "    print(j)\n",
    "    merged_test.to_csv(f\"{file_path}//{sensor_id_list[n]}_total\")\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "## Create one big Dataframe with all data for all time\n",
    "\n",
    "# match the Sensor IDs with their acronyms\n",
    "\n",
    "path_acronym_excel = os.getcwd()\n",
    "\n",
    "#####################################\n",
    "# SEEWEG\n",
    "\n",
    "acronym_list = pd.read_excel(f\"{path_acronym_excel}//Acronyms.xlsx\", usecols=[\"Sensor ID\", \"name\"],dtype={\"Sensor ID\": str})\n",
    "acronym_list = acronym_list.dropna()\n",
    "\n",
    "for n in range(len(acronym_list)):\n",
    "#n=0\n",
    "    merged_test = pd.DataFrame()\n",
    "    for j in range(len(date_list)):\n",
    "        test = read_csv_filtered(file_path, date_list[j], acronym_list.iloc[n,0])\n",
    "        merged_test = pd.concat([merged_test, test])\n",
    "        #print(len(merged_test)-len(test))\n",
    "        \n",
    "    if any(merged_test['status'] != 'Good (0x00000000)'):\n",
    "        warnings.warn(\"Warning: Some values in the 'Status' column are different from 'Good (0x00000000)'.\")\n",
    "    print(f\"Data of {j} days was stored for sensor ID {acronym_list.iloc[n,0]}\")\n",
    "\n",
    "    # Assign new column names\n",
    "    merged_test = merged_test.drop(columns=merged_test.columns[-1])         # drop the \"status\" column\n",
    "    merged_test.columns = [acronym_list.iloc[n,1]]                          # rename the value column as acronym\n",
    "    merged_test.to_csv(f\"{file_path}//{acronym_list.iloc[n,1]}-{acronym_list.iloc[n,0]}-total.csv\")#\"\"\"\n",
    "\n",
    "\n",
    "#####################################\n",
    "# MENDEL\n",
    "\"\"\"acronym_list = pd.read_excel(f\"{path_acronym_excel}//Acronyms.xlsx\", usecols=[\"Sensor ID M\", \"name M\"],dtype={\"Sensor ID M\": str})\n",
    "acronym_list = acronym_list.dropna()\n",
    "\n",
    "for n in range(len(acronym_list)):\n",
    "#n=0\n",
    "    merged_test = pd.DataFrame()\n",
    "    for j in range(len(date_list)):\n",
    "        test = read_csv_filtered(file_path, date_list[j], acronym_list.iloc[n,0])\n",
    "        merged_test = pd.concat([merged_test, test])\n",
    "        #print(len(merged_test)-len(test))\n",
    "        \n",
    "    if any(merged_test['status'] != 'Good (0x00000000)'):\n",
    "        warnings.warn(\"Warning: Some values in the 'Status' column are different from 'Good (0x00000000)'.\")\n",
    "    #print(f\"Data of {j} days was stored for sensor ID {acronym_list.iloc[n,0]}\")\n",
    "\n",
    "    # Assign new column names\n",
    "    merged_test = merged_test.drop(columns=merged_test.columns[-1])         # drop the \"status\" column\n",
    "    merged_test.columns = [acronym_list.iloc[n,1]]                          # rename the value column as acronym\n",
    "    merged_test.to_csv(f\"{file_path}//{acronym_list.iloc[n,1]}-{acronym_list.iloc[n,0]}-total\")\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf_b-7367-total\n",
      "mf_b-7367-total\n",
      "1\n",
      "pel_hp1-4615-total\n",
      "pel_hp1-4615-total\n",
      "2\n",
      "pel_hp2-4619-total\n",
      "pel_hp2-4619-total\n",
      "3\n",
      "s_b-4417-total\n",
      "s_b-4417-total\n",
      "4\n",
      "s_load_pump-4593-total\n",
      "s_load_pump-4593-total\n",
      "5\n",
      "s_sl_pump-4603-total\n",
      "s_sl_pump-4603-total\n",
      "6\n",
      "s_sol_pump-4550-total\n",
      "s_sol_pump-4550-total\n",
      "7\n",
      "t_b_flow-4382-total\n",
      "t_b_flow-4382-total\n",
      "8\n",
      "t_b_return-4280-total\n",
      "t_b_return-4280-total\n",
      "9\n",
      "t_hc1_flow-4370-total\n",
      "t_hc1_flow-4370-total\n",
      "10\n",
      "t_hc1_return-4262-total\n",
      "t_hc1_return-4262-total\n",
      "11\n",
      "t_hc2_flow-4376-total\n",
      "t_hc2_flow-4376-total\n",
      "12\n",
      "t_hc2_return-4268-total\n",
      "t_hc2_return-4268-total\n",
      "13\n",
      "t_hctot_flow-14108-total\n",
      "t_hctot_flow-14108-total\n",
      "14\n",
      "t_hctot_return-14109-total\n",
      "t_hctot_return-14109-total\n",
      "15\n",
      "t_hp1_flow-4406-total\n",
      "t_hp1_flow-4406-total\n",
      "16\n",
      "t_hp1_hg_flow-4364-total\n",
      "t_hp1_hg_flow-4364-total\n",
      "17\n",
      "t_hp1_hg_return-4256-total\n",
      "t_hp1_hg_return-4256-total\n",
      "18\n",
      "t_hp1_return-4310-total\n",
      "t_hp1_return-4310-total\n",
      "19\n",
      "t_hp2_flow-4412-total\n",
      "t_hp2_flow-4412-total\n",
      "20\n",
      "t_hp2_return-4316-total\n",
      "t_hp2_return-4316-total\n",
      "21\n",
      "t_load_flow-4388-total\n",
      "t_load_flow-4388-total\n",
      "22\n",
      "t_load_return-4286-total\n",
      "t_load_return-4286-total\n",
      "23\n",
      "t_lsp1-4244-total\n",
      "t_lsp1-4244-total\n",
      "24\n",
      "t_lsp2-4238-total\n",
      "t_lsp2-4238-total\n",
      "25\n",
      "t_lsp3-4232-total\n",
      "t_lsp3-4232-total\n",
      "26\n",
      "t_lsp4-14110-total\n",
      "t_lsp4-14110-total\n",
      "27\n",
      "t_lsp5-4250-total\n",
      "t_lsp5-4250-total\n",
      "28\n",
      "t_sl_flow-14106-total\n",
      "t_sl_flow-14106-total\n",
      "29\n",
      "t_sl_return-14107-total\n",
      "t_sl_return-14107-total\n",
      "30\n",
      "t_sol1_return-4334-total\n",
      "t_sol1_return-4334-total\n",
      "31\n",
      "t_sol2_return-4340-total\n",
      "t_sol2_return-4340-total\n",
      "32\n",
      "t_sol_collector-4322-total\n",
      "t_sol_collector-4322-total\n",
      "33\n",
      "t_sol_flow-4328-total\n",
      "t_sol_flow-4328-total\n",
      "34\n",
      "t_ssp1-4358-total\n",
      "t_ssp1-4358-total\n",
      "35\n",
      "t_ssp2-14104-total\n",
      "t_ssp2-14104-total\n",
      "36\n",
      "t_ssp3-4352-total\n",
      "t_ssp3-4352-total\n",
      "37\n",
      "t_ssp4-14105-total\n",
      "t_ssp4-14105-total\n",
      "38\n",
      "t_ssp5-4346-total\n",
      "t_ssp5-4346-total\n",
      "39\n",
      "vdot_b-4428-total\n",
      "vdot_b-4428-total\n",
      "40\n",
      "vdot_b_gas-4414-total\n",
      "vdot_b_gas-4414-total\n",
      "41\n",
      "vdot_hc1_flow-4481-total\n",
      "vdot_hc1_flow-4481-total\n",
      "42\n",
      "vdot_hc2_flow-4511-total\n",
      "vdot_hc2_flow-4511-total\n",
      "43\n",
      "vdot_hp1_flow-4451-total\n",
      "vdot_hp1_flow-4451-total\n",
      "44\n",
      "vdot_hp1_hg_flow-4447-total\n",
      "vdot_hp1_hg_flow-4447-total\n",
      "45\n",
      "vdot_hp2_flow-4467-total\n",
      "vdot_hp2_flow-4467-total\n",
      "46\n",
      "vdot_load-4587-total\n",
      "vdot_load-4587-total\n",
      "47\n",
      "vdot_sol-4544-total\n",
      "vdot_sol-4544-total\n",
      "48\n",
      "vent_hc1-4473-total\n",
      "vent_hc1-4473-total\n",
      "49\n",
      "vent_hc2-4503-total\n",
      "vent_hc2-4503-total\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "## create one file with all data of one building from csv files (one per sensor)\n",
    "# resulting files\n",
    "    # MENDEL:       C:\\Users\\sophi\\repos\\repos_thesis\\Buildings\\measurements\\mendel_data\\mendel-data-merged.csv\n",
    "    # SEEWEG:       C:\\Users\\sophi\\repos\\repos_thesis\\Buildings\\measurements\\seeweg_data\\seeweg-data-merged.csv\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "building_name = \"mendel\"        # name of the folder in the \"measurements\" folder\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), f\"measurements\\{building_name}_data\")\n",
    "\n",
    "csv_names = os.listdir(file_path)\n",
    "\n",
    "total_merged = pd.DataFrame()\n",
    "\n",
    "n=0\n",
    "for i in range(1, len(csv_names)):\n",
    "    \n",
    "    print(csv_names[i])\n",
    "    # Read CSV file into DataFrame\n",
    "    df = pd.read_csv(f\"{file_path}\\\\{csv_names[i]}\", parse_dates=['timestamp'],index_col='timestamp') #header=True, )\n",
    "    total_merged = pd.concat([total_merged, df], axis=1)\n",
    "    print(csv_names[i])\n",
    "    n += 1\n",
    "    print(n)\n",
    "\n",
    "total_merged.to_csv(f\"{file_path}//{building_name}-data-merged.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
